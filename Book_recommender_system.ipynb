{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nakulcj7/Book-recommendation-system/blob/main/Book_recommender_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Book Recommendation System\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the last few decades, with the rise of Youtube, Amazon, Netflix, and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\n",
        "\n",
        "\n",
        "In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy, or anything else depending on industries).\n",
        "\n",
        "\n",
        "Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors. The main objective is to create a book recommendation system for users.\n",
        "\n",
        "The project concerns the books recommendation system. It includes data analysis, data preparation and explored three kind of recommendations - the simplest recommendations, content-based filtering and collaborative filtering (KNN model and matrix factorization). The final result will show that the user can input one book's name or author then the system can provide the other most possible books that he can to read."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Nakulcj7/Book-recommendation-system/blob/main/Book_recommender_system.ipynb"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy, or anything else depending on industries).\n",
        "\n",
        "Recommendation systems are used in hundreds of different services - everywhere from online shopping to music to movies. Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors.\n",
        "\n",
        "The main objective of our project is to create book recommendation systems for users on various approaches ."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required libraries\n",
        "#Data wrangling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_colwidth\",1000)#setting maximum column width\n",
        "#data visualization\n",
        "import seaborn as sns\n",
        "sns.set_style('white')\n",
        "import matplotlib.pyplot as plt\n",
        "#To create wordcloud\n",
        "plt.rcParams[\"figure.figsize\"] = (8,8)"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ta6WGVl1w5Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the required datasets\n",
        "books_df = pd.read_csv('/content/drive/MyDrive/Almabetter/Books.csv',low_memory=False,error_bad_lines=False,encoding=\"latin-1\")\n",
        "rating_df = pd.read_csv('/content/drive/MyDrive/Almabetter/Ratings.csv',low_memory=False,error_bad_lines=False,encoding=\"latin-1\")\n",
        "users_df = pd.read_csv('/content/drive/MyDrive/Almabetter/Users.csv',low_memory=False,error_bad_lines=False,encoding=\"latin-1\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "users_df.head(3)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.head(3)"
      ],
      "metadata": {
        "id": "ERlg7ZXlxVsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df.head(3)"
      ],
      "metadata": {
        "id": "IwqMb2EYxaEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shapes of all the datasets\n",
        "print('Shape of Users: {}, Books: {} and Ratings: {}'.format(users_df.shape, books_df.shape, rating_df.shape))"
      ],
      "metadata": {
        "id": "6MAvAPJgxvuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Books data"
      ],
      "metadata": {
        "id": "Ww69jAyw1w_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Description\n",
        "\n",
        "Books are identified by their respective ISBN. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given (Book-Title, Book-Author, Year-Of-Publication, Publisher), obtained from Amazon Web Services. Note that in the case of several authors, only the first is provided. URLs linking to cover images are also given, appearing in three different flavors (Image-URL-S, Image-URL-M, Image-URL-L), i.e., small, medium, large. These URLs point to the Amazon website."
      ],
      "metadata": {
        "id": "Alj7FSAy2BF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.head()"
      ],
      "metadata": {
        "id": "ASEdd4Wg2TTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('This shape of Books datasheet is : ',books_df.shape)\n",
        "print('='*30)\n",
        "print('This shape of Ratings datasheet is : ',rating_df.shape)\n",
        "print('='*30)\n",
        "print('This shape of Users datasheet is : ',users_df.shape)"
      ],
      "metadata": {
        "id": "7c-CZx-o2e5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(books_df.info())"
      ],
      "metadata": {
        "id": "Nfk40lxv2lxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.describe()"
      ],
      "metadata": {
        "id": "_1OsLMaB2uAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing value percentage\n",
        "print(books_df.isnull().sum()/len(books_df)*100)"
      ],
      "metadata": {
        "id": "AzHI3uwd2zU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking  for  null value in book author\n",
        "books_df[books_df['Book-Author'].isna()]"
      ],
      "metadata": {
        "id": "28VfUjRr26nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling the null value\n",
        "books_df.loc[187689, 'Book-Author'] = 'Larissa Anne Downes'"
      ],
      "metadata": {
        "id": "eDZQqvpD2_Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking null values in publisher\n",
        "books_df[books_df['Publisher'].isna()]"
      ],
      "metadata": {
        "id": "A3tD_oIY3IkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing NaNs with correct  values\n",
        "books_df.loc[128890, 'Publisher'] = 'Mundania Press LLC'\n",
        "books_df.loc[129037, 'Publisher'] = 'Bantam'"
      ],
      "metadata": {
        "id": "XdY9VsFh3k2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#insepcting the values in year of publication\n",
        "books_df['Year-Of-Publication'].unique()"
      ],
      "metadata": {
        "id": "yaLt608E3qor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name of few publication companies have been incorrectly put in this column.There are values such as 0 ,2024,2030 etc. which is also not possible .Let's rectify these mistakes"
      ],
      "metadata": {
        "id": "z-Zgo5a63vyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correcting this error\n",
        "books_df[books_df['Year-Of-Publication'] == 'DK Publishing Inc']"
      ],
      "metadata": {
        "id": "6YQB1Hvv34Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# on searching for these  books we came to know about its authors\n",
        "#ISBN '078946697X'\n",
        "books_df.loc[books_df.ISBN == '078946697X','Year-Of-Publication'] = 2000\n",
        "books_df.loc[books_df.ISBN == '078946697X','Book-Author'] = \"Michael Teitelbaum\"\n",
        "books_df.loc[books_df.ISBN == '078946697X','Publisher'] = \"DK Publishing Inc\"\n",
        "books_df.loc[books_df.ISBN == '078946697X','Book-Title'] = \"DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)\"\n",
        "\n",
        "#ISBN '0789466953'\n",
        "books_df.loc[books_df.ISBN == '0789466953','Year-Of-Publication'] = 2000\n",
        "books_df.loc[books_df.ISBN == '0789466953','Book-Author'] = \"James Buckley\"\n",
        "books_df.loc[books_df.ISBN == '0789466953','Publisher'] = \"DK Publishing Inc\"\n",
        "books_df.loc[books_df.ISBN == '0789466953','Book-Title'] = \"DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)\""
      ],
      "metadata": {
        "id": "ek3YKZ1x3-b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the rows having 'Gallimard' as yearOfPublication\n",
        "books_df.loc[books_df['Year-Of-Publication'] == 'Gallimard',:]"
      ],
      "metadata": {
        "id": "jwiH3z954E-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.loc[books_df.ISBN=='2070426769','Year-Of-Publication']=2003\n",
        "books_df.loc[books_df.ISBN=='2070426769','Book-Author']='Jean-Marie Gustave Le ClÃ?Â©zio'\n",
        "books_df.loc[books_df.ISBN=='2070426769','Publisher']='Gallimard'\n",
        "books_df.loc[books_df.ISBN=='2070426769','Book-Title']=\"Peuple du ciel, suivi de 'Les Bergers\""
      ],
      "metadata": {
        "id": "XAJpBf4Y4LK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if the corrections are in place\n",
        "books_df.loc[books_df['ISBN'].isin(['2070426769','0789466953','078946697X'])]"
      ],
      "metadata": {
        "id": "xuZp4hum4PcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing dtype of year of publication\n",
        "books_df['Year-Of-Publication'] =books_df['Year-Of-Publication'].astype(int)"
      ],
      "metadata": {
        "id": "I5rEunhV4Syo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# something is off about years of publication like:\n",
        "books_df[(books_df['Year-Of-Publication'] > 0) & (books_df['Year-Of-Publication'] < 1800)]"
      ],
      "metadata": {
        "id": "AWtwmShz4WKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing with correct  values\n",
        "books_df.loc[books_df.ISBN=='\t9643112136','Year-Of-Publication'] = 2010\n",
        "books_df.loc[books_df.ISBN=='964442011X', 'Year-Of-Publication'] = 1991"
      ],
      "metadata": {
        "id": "MMh9uZOZ4Zk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sustituting np.Nan in rows with year=0 or  greater than the current year,2022.\n",
        "books_df.loc[(books_df['Year-Of-Publication'] > 2022) | (books_df['Year-Of-Publication'] == 0),'Year-Of-Publication'] = np.NAN\n",
        "\n",
        "# replacing NaN values with median value of Year-Of-Publication\n",
        "books_df['Year-Of-Publication'].fillna(int(books_df['Year-Of-Publication'].median()), inplace=True)"
      ],
      "metadata": {
        "id": "3Zd7qHOR4dBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df['Book-Author'].value_counts()"
      ],
      "metadata": {
        "id": "AnDMSYVb4gpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df['Publisher'].value_counts()"
      ],
      "metadata": {
        "id": "MJ4Ax_3b4lVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspecting the missing values in 'Publisher' column\n",
        "books_df.loc[books_df.Publisher.isnull(),:]"
      ],
      "metadata": {
        "id": "hGhvF89U4qYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uppercasing the ISBN numbers and Book-Author name\n",
        "books_df['ISBN']=books_df['ISBN'].str.upper()\n",
        "books_df['Book-Author']=books_df['Book-Author'].str.upper()"
      ],
      "metadata": {
        "id": "wQ3AVyFw4vgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df[books_df['Book-Title']=='Emma']"
      ],
      "metadata": {
        "id": "15vNInuj4y_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ISBN numbers for books with the same title and author would change if the year of release (revised editions),regional versions or publishing companies are different. So, let's look for rows where entire column values are identical."
      ],
      "metadata": {
        "id": "o1zRDClC43Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for duplicates in books_df\n",
        "books_df[books_df.duplicated()]"
      ],
      "metadata": {
        "id": "XAu7B01_47AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the rows with the entire column values are duplicated\n",
        "books_df.drop_duplicates(keep=\"first\",inplace=True)\n",
        "books_df.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "p71ckWUD4_AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the image urls\n",
        "books_df.drop(columns=['Image-URL-S','Image-URL-M','Image-URL-L'],inplace=True)"
      ],
      "metadata": {
        "id": "V7hPrUmi5Bx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.info()"
      ],
      "metadata": {
        "id": "plHLGQJX5Hd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Users Data"
      ],
      "metadata": {
        "id": "e7t8PLXbCx-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data description**\n",
        "\n",
        "Contains the users. Note that user IDs (User-ID) have been anonymized and map to integers. Demographic data is provided (Location, Age) if available. Otherwise, these fields contain NULL values."
      ],
      "metadata": {
        "id": "TYJ0XyHgC2lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the top 10 and bottom 10 rows of the dataframe\n",
        "pd.concat([users_df.head(10),users_df.tail(10)],axis=0)"
      ],
      "metadata": {
        "id": "l-e4Rg8wDAlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspecting the columns in users_df\n",
        "users_df.info()"
      ],
      "metadata": {
        "id": "OB0HsrQrDP7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    There are records of 278858 users in this dataframe.There are 3 columns in this dataframe.\n",
        "*   The 'Age' column has null values\n",
        "\n"
      ],
      "metadata": {
        "id": "B98lws8bDTjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for duplicates in users_df\n",
        "users_df[users_df['User-ID'].duplicated()].sum()"
      ],
      "metadata": {
        "id": "7ml37iu0DcjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Percentage of missing values in users_df\n",
        "print(users_df.isnull().sum()/len(users_df)*100)"
      ],
      "metadata": {
        "id": "fqWprKfVDgGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    The 39.7% of values in the 'Age' column are missing/NaN values\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kLjjy8P1DkRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#summarizing data in 'Age' column\n",
        "users_df['Age'].describe()"
      ],
      "metadata": {
        "id": "oaa7o-rYDqxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The maximum value in the 'Age' column is 244. This is certainly an outlier.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ho4pPubjELoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogram showing distribution of ages\n",
        "fig=plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "sns.histplot(x='Age',data=users_df)\n",
        "\n",
        "#boxplot of Age column\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(x='Age',data=users_df)"
      ],
      "metadata": {
        "id": "yq2uDeIhEZw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Most of the users are from the age group 25-50\n",
        "*   It is highly unlikely to have users under the age of 4 and above 100.The peaks near 0 and 100 in the kdeplot indicates that there are some outlier values in the 'Age' column\n",
        "\n"
      ],
      "metadata": {
        "id": "oElQJBcsEf9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "It is highly unlikely to have users of age above 95 and below 4 in this case.Let's replace these values with np.nan\n"
      ],
      "metadata": {
        "id": "qp4iCR2NEruV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing the outliers in 'Age' with NaN value\n",
        "users_df.loc[(users_df['Age']>95)|(users_df['Age']<4),'Age']=np.nan"
      ],
      "metadata": {
        "id": "608ahX8iEvi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the current number of missing values in  'Age' column\n",
        "print('The number of missing values is ',users_df['Age'].isnull().sum())\n",
        "#Imputing such a large amount of null values will mean/mode/median will drastically change the distribution\n",
        "users_df['Age'].describe()"
      ],
      "metadata": {
        "id": "uhtoKzPEEzxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a normal distribution pd.Series to fill Nan values with\n",
        "normal_age_series = pd.Series(np.random.normal(loc=users_df.Age.mean(), scale=users_df.Age.std(), size=users_df[users_df.Age.isna()]['User-ID'].count()))\n",
        "\n",
        "# take the absolute value of temp_age_series\n",
        "abs_age_series=np.abs(normal_age_series)\n",
        "\n",
        "# sort users df so as NaN values in age to be first and reset index to match with index of abs_age_series. Then using fillna()\n",
        "users_df = users_df.sort_values('Age',na_position='first').reset_index(drop=True)\n",
        "users_df.Age.fillna(round(abs_age_series), inplace = True)"
      ],
      "metadata": {
        "id": "I_WTDoNkE3xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after imputation\n",
        "users_df.Age.describe()"
      ],
      "metadata": {
        "id": "WTMOmyDEE813"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#percentage of missing values in 'Age' column\n",
        "(users_df['Age'].isnull().sum()/len(users_df))*100"
      ],
      "metadata": {
        "id": "rKrOnR68FBAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def age_group(age):\n",
        "  '''\n",
        "  defines the age group of users\n",
        "  '''\n",
        "  if age<13:\n",
        "    x='Children'\n",
        "  elif age>=13 and age<18:\n",
        "    x='Teens'\n",
        "  elif age>=18 and age<36:\n",
        "    x='Youth'\n",
        "  elif age>=36 and age<56:\n",
        "    x='Middle aged adults'\n",
        "  else:\n",
        "    x='Elderly'\n",
        "  return x"
      ],
      "metadata": {
        "id": "Zr0F5tDUFFBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df['Age_group']=users_df['Age'].apply(lambda x: age_group(x))"
      ],
      "metadata": {
        "id": "2pg1MzRmFL_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The missing values in the 'Age' column have been imputed with values from a normal distribution\n",
        "\n",
        "Now let's inspect the 'Location' column.\n"
      ],
      "metadata": {
        "id": "3kh8M_EVFQGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#number of unique values in 'Location'\n",
        "users_df['Location'].nunique()"
      ],
      "metadata": {
        "id": "vzW4daVCFUFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting the country names from users_df\n",
        "for i in users_df:\n",
        "    users_df['Country']=users_df.Location.str.extract(r'\\,+\\s?(\\w*\\s?\\w*)\\\"*$')"
      ],
      "metadata": {
        "id": "nViUCGSBFZLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the country names\n",
        "set(users_df['Country'])"
      ],
      "metadata": {
        "id": "QnkCKQfrFcqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correcting the mispelled country names\n",
        "users_df.loc[users_df['Country'].isin(['australii','autralia','western australia']), 'Country'] = 'australia'\n",
        "users_df.loc[users_df['Country'].isin(['unite states','01776','02458','19104','23232','30064','85021','87510','united sates','united staes','united state','united statea','united stated','america'\n",
        "                                      'united stated of america','united states','united states of america','us','us of a','us virgin islands',\n",
        "                                      'usa  canada','usa currently living in england','uusa','usaa','wonderful usa','california','orange co']), 'Country'] = 'usa'\n",
        "users_df.loc[users_df['Country'].isin(['united kindgdom', 'united kindgonm','united kingdom','u k']), 'Country'] = 'uk'\n",
        "users_df.loc[users_df['Country'].isin(['the philippines', 'philippines', 'philippinies', 'phillipines', 'phils', 'phippines']), 'Country'] = 'philippines'\n",
        "users_df.loc[users_df['Country'].isin(['','xxxxxx','universe','nowhere','x','y','a','öð¹ú','the','unknown',np.nan,'n/a','aaa','z','somewherein space']), 'Country'] = 'others'\n",
        "users_df.loc[users_df['Country'].isin([ 'italia','italien','itlay']), 'Country'] = 'italy'\n",
        "users_df.loc[users_df['Country'].isin([ ' china öð¹ú','chinaöð¹ú','chian']), 'Country'] = 'china'\n",
        "users_df['Country'].replace([ 'the gambia','the netherlands','geermany','srilanka','saudia arabia','brasil','_ brasil','indiai','malaysian','hongkong','russian federation'],\n",
        "                            ['gambia','netherlands','germany','sri lanka','saudi arabia','brazil','brazil','india','malaysia','hong kong','russia'],inplace=True)\n",
        ""
      ],
      "metadata": {
        "id": "XQTHbf-EFtwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the country names to uppercase\n",
        "users_df['Country']=users_df['Country'].str.upper()"
      ],
      "metadata": {
        "id": "CXUyjJ0oF7uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the column 'Location'\n",
        "users_df.drop('Location',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "j-q9M4kQGAuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.columns"
      ],
      "metadata": {
        "id": "GsOpvxe-GE7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.Country.value_counts()"
      ],
      "metadata": {
        "id": "R3E2_KCDGPdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Ratings data"
      ],
      "metadata": {
        "id": "Jy7OqTu8I6BG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data description**\n",
        "\n",
        "Contains the book rating information. Ratings (Book-Rating) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0."
      ],
      "metadata": {
        "id": "UmH2RNRzJCuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the first 5 rows\n",
        "rating_df.head()"
      ],
      "metadata": {
        "id": "KrJAt_3CJV4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df.info()"
      ],
      "metadata": {
        "id": "VeaUbqM8gZH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking null values\n",
        "rating_df.isna().sum()"
      ],
      "metadata": {
        "id": "co60xIVfgdbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for unique user ids and isbn values\n",
        "print('Number of unique user ids is {} and ISBN no. is {}'.format(rating_df['User-ID'].nunique(), rating_df['ISBN'].nunique()))"
      ],
      "metadata": {
        "id": "JWHaJRWzgjQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means that many users are buying multiple books. Also some books are really famous and hence are bought by multiple users."
      ],
      "metadata": {
        "id": "MsPRJUa4gnhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making all the ISBN no. uppercase\n",
        "rating_df['ISBN'].apply(lambda x: x.upper())"
      ],
      "metadata": {
        "id": "q4lAKZaigtL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for duplicates\n",
        "rating_df[rating_df.duplicated()].sum()"
      ],
      "metadata": {
        "id": "21mugQWJgwl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see if all the books in rating_df are also in books_df\n",
        "rating_df_new = rating_df[rating_df['ISBN'].isin(books_df['ISBN'])]"
      ],
      "metadata": {
        "id": "BGaNgw9Cgzfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of rating_df: {} and rating_df_new: {}'.format(rating_df.shape, rating_df_new.shape))"
      ],
      "metadata": {
        "id": "RAigd9RSg4Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# book ratings\n",
        "rating_df_new['Book-Rating'].value_counts().reset_index()"
      ],
      "metadata": {
        "id": "Apg5TCKEg7Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can see for explicit ratrings that rating is 8 which is received by most number of books followed by ration 10.There are 646974 iimplicitly rated books.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u2wSRDvng-ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# most popular books\n",
        "rating_df_new.groupby('ISBN')['Book-Rating'].count().reset_index().sort_values(by='Book-Rating', ascending=False)[:10]"
      ],
      "metadata": {
        "id": "J3O0Rq4siPCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But this contains both explicit and implicit rating, so we need to seperate them to get better idea.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BbSrt2wSqx-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explicit_rating = rating_df_new[rating_df_new['Book-Rating'] != 0]\n",
        "implicit_rating = rating_df_new[rating_df_new['Book-Rating'] == 0]\n",
        "print('Shape of explicit rating: {} and implicit rating: {}'.format(explicit_rating.shape, implicit_rating.shape))"
      ],
      "metadata": {
        "id": "P61IHoWyrIcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# most purchased books including the implicitely rated books\n",
        "rating_df_new.groupby('ISBN')['User-ID'].count().reset_index().sort_values(by='User-ID', ascending=False)[:10]['ISBN'].values"
      ],
      "metadata": {
        "id": "Np1ToB3HrNQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the book names corresponding to these ISBNs\n",
        "isbn_nums = ['0971880107', '0316666343', '0385504209', '0060928336',\n",
        "       '0312195516', '044023722X', '0142001740', '067976402X',\n",
        "       '0671027360', '0446672211']\n",
        "books_df[books_df['ISBN'].isin(isbn_nums)]"
      ],
      "metadata": {
        "id": "11VljlhrrQUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# most popular explicitely rated books\n",
        "explicit_rating.groupby('ISBN')['Book-Rating'].count().reset_index().sort_values(by='Book-Rating', ascending=False)[:10]"
      ],
      "metadata": {
        "id": "w1G5tWJIrolZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the book names corresponding to these ISBNs\n",
        "isbn_nums = ['0316666343', '0971880107', '0385504209', '0312195516', '0060928336']\n",
        "books_df[books_df['ISBN'].isin(isbn_nums)]"
      ],
      "metadata": {
        "id": "N0BUIjm8rr3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore the most popular book is 'The Lovely Bones: A Novel'"
      ],
      "metadata": {
        "id": "1y3vp4p8rwbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging Datasets"
      ],
      "metadata": {
        "id": "T4HKbh_fsFKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for the rating dataset, we are only taking the explicit rating dataset\n",
        "df = pd.merge(books_df, explicit_rating, on='ISBN', how='inner')\n",
        "df = pd.merge(df, users_df, on='User-ID', how='inner')"
      ],
      "metadata": {
        "id": "KMXdjtF1sHqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of the merged dataframe 'df'\n",
        "df.shape"
      ],
      "metadata": {
        "id": "ebAuPmHtsOTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the top 3 rows of df\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "3xYEuOAWsRNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "2c_CfSVtsU5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "8rgICiUVsdxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# most popular rating\n",
        "plt.figure(figsize=[8,5])\n",
        "plt.rc('font', size=12)\n",
        "plt.title('\\nMost popular ratings\\n')\n",
        "sns.countplot(data=df, x='Book-Rating',palette='Set2')"
      ],
      "metadata": {
        "id": "jZnWq5Twsfip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Most of users have given above 4 ratings to books\n",
        "*   8 is the most common rating given by users\n",
        "\n"
      ],
      "metadata": {
        "id": "BTzzihaMsn4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# top 5 most popular books\n",
        "\n",
        "popular = df.groupby('Book-Title')['Book-Rating'].count().reset_index().sort_values(by='Book-Rating', ascending=False)[:5]\n",
        "popular.columns = ['Book-Title', 'Count']\n",
        "\n",
        "plt.figure(figsize=[8, 5])\n",
        "plt.rc('font', size=12)\n",
        "plt.title('\\nMost popular books\\n')\n",
        "sns.barplot(data=popular, y='Book-Title', x='Count',palette='Set2')"
      ],
      "metadata": {
        "id": "X1vtxgSgtJw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    The book which has been rated by most number of users is 'The Lovely Bones'\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gCx12QHUtTEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# most popular book authors\n",
        "author = df.groupby('Book-Author')['Book-Rating'].count().reset_index().sort_values(by='Book-Rating', ascending=False)[:10]\n",
        "plt.figure(figsize=[8, 5])\n",
        "plt.rc('font', size=12)\n",
        "plt.title('\\nMost popular Authors\\n')\n",
        "sns.barplot(data=author, y='Book-Author', x='Book-Rating',palette='Set2')"
      ],
      "metadata": {
        "id": "cEBnbSdDtlYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Top book author with respect to the number of ratings is Stephen King\n",
        "\n"
      ],
      "metadata": {
        "id": "vbUSZkASt5YC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Age distribution of users\n",
        "age_df=users_df[users_df['User-ID'].isin(list(df['User-ID'].unique()))]\n",
        "sns.distplot(age_df.Age)"
      ],
      "metadata": {
        "id": "72QOEl90uCYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The majority of readers are between the ages of 25 and 40.\n",
        "*   Readers who are 80 to 100 years old make up a tiny minority.\n",
        "\n"
      ],
      "metadata": {
        "id": "UHV0RPHiuGxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# countries with most readers\n",
        "countries = df.groupby('Country')['User-ID'].nunique().reset_index().sort_values(by='User-ID', ascending=False)[:10]\n",
        "sns.barplot(data=countries, y='Country', x='User-ID',palette='Set2')\n",
        "plt.xlabel('No of users')"
      ],
      "metadata": {
        "id": "MihWtsLguPvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Most of the readers are from the United States\n",
        "\n"
      ],
      "metadata": {
        "id": "lMJ3LIzpuTYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How many users have rated atleast 1 book?\n",
        "df['User-ID'].value_counts()"
      ],
      "metadata": {
        "id": "KbeyQ6iDuYsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 68080 users who have rated atleast one book"
      ],
      "metadata": {
        "id": "mm_Wowg9ufnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('User-ID')['Book-Rating'].count().describe()"
      ],
      "metadata": {
        "id": "qbRnJKwJujOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Publisher with most books\n",
        "\n",
        "publishers = df.groupby('Publisher')['Book-Title'].count().reset_index().sort_values(by='Book-Title', ascending=False)[:10]\n",
        "plt.figure(figsize=[8, 5])\n",
        "sns.barplot(data=publishers, x='Book-Title', y='Publisher',palette='Set2')"
      ],
      "metadata": {
        "id": "I2_MiAlKumzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    Ballantine Books is most popular publisher based on the number of users who have rated their books\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YFeiNWYjup9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(20,14))\n",
        "i=1\n",
        "for group  in ['Children','Teens','Youth','Middle aged adults','Elderly']:\n",
        "  age_df=df.loc[df['Age_group']==group].groupby(['Book-Title']).agg(No_of_users=('User-ID','nunique'),total_rating=('Book-Rating','sum')).reset_index()\n",
        "  plt.subplot(5,2,i)\n",
        "  age_df.sort_values(by='No_of_users',ascending=False,inplace=True)\n",
        "  sns.barplot(x='No_of_users',y='Book-Title',palette='Paired',data=age_df.head(5))\n",
        "  plt.title('Top 5 Popular books among  {}'.format(group),size=16)\n",
        "  i+=1\n",
        "  plt.subplot(5,2,i)\n",
        "  age_df.sort_values(by='total_rating',ascending=False,inplace=True)\n",
        "  sns.barplot(x='total_rating',y='Book-Title',palette='Set2',data=age_df.head(5))\n",
        "  plt.title('Top rated books by {} '.format(group),size=16)\n",
        "  i+=1\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "5fUgVDy9uv4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "bZSfraKOuz42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "EDA CONCLUSIONS"
      ],
      "metadata": {
        "id": "RakrUUleu3Gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The Lovely Bones: A Novel and Wild Animus are the two most read books\n",
        "\n",
        "*   Most popular book author based on the number of ratings is Stephan King.\n",
        "\n",
        "*   \n",
        "Ballantine Books and Pocket are the top publishers based on the number of ratings that their books have received.\n",
        "*   The majority of readers are between the ages of 20 and 40.\n",
        "\n",
        "\n",
        "*   \n",
        "The majority of readers who have given the books ratings are from the United States and Canada\n",
        "\n",
        "\n",
        "*   Regardless of the age group, The Lovely Bones and Wild animus appear on lists of the top-rated books.\n",
        "\n"
      ],
      "metadata": {
        "id": "OUu1zupgu7Wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Popularity Based Recommendation System\n",
        "\n",
        "\n",
        "\n",
        "It is a type of recommendation system that bases choices on factors like popularity and/or current trends."
      ],
      "metadata": {
        "id": "SLFE7t_tQKMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Popularity based recommendation system"
      ],
      "metadata": {
        "id": "7xIx6_vwQXV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for getting most popular recommendations\n",
        "\n",
        "def most_popular(df, n):\n",
        "  if n >= 1 and n <= len(df):\n",
        "    popular = df.groupby('ISBN')['Book-Rating'].count().reset_index().sort_values(by='Book-Rating', ascending=False).head(n)\n",
        "    return pd.merge(popular, books_df, on='ISBN')\n",
        "  return 'Please enter a valid value of n!'"
      ],
      "metadata": {
        "id": "m5qjVkw-Qsoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_popular(df, 3)"
      ],
      "metadata": {
        "id": "AweuANFnQv0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Country-based book recommendation"
      ],
      "metadata": {
        "id": "QrHJoQd2QznZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for getting most popular recommendations country wise\n",
        "\n",
        "def country_popular(df, country):\n",
        "  if country in list(df.Country.unique()):\n",
        "    return most_popular(df[df['Country'] == country], 5) # calling most_popular function to get popular recommendations\n",
        "  return 'This country is not present in the dataset. Please enter some other country.'"
      ],
      "metadata": {
        "id": "cfAEdzaJQ3cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_popular(df, 'INDIA')"
      ],
      "metadata": {
        "id": "cL0v5a8RQ6ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weighted average rating method"
      ],
      "metadata": {
        "id": "S2HG_65uQ-Jy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Using Weighted average for each Book’s Average Rating\n",
        "\n",
        "W = (Rv + Cm)/(v + m)\n",
        "\n",
        "where\n",
        "\n",
        "W= Weighted Rating\n",
        "\n",
        "R = Average of the Books rating\n",
        "\n",
        "v = No of people who have rated the books(number of votes)\n",
        "\n",
        "m = minimum no of votes to be listed\n",
        "\n",
        "C = the mean rating across all the books\n"
      ],
      "metadata": {
        "id": "7DzgSl6yRBv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#finding the average rating and number of votes received by books\n",
        "df_relevant_data = df.groupby(['Book-Title','Book-Author'],as_index=False).agg(avg_rating=('Book-Rating','mean'),ratings_count=('Book-Rating','count'))\n",
        "v=df_relevant_data['ratings_count']\n",
        "R=df_relevant_data['avg_rating']\n",
        "C=df_relevant_data['avg_rating'].mean()\n",
        "m=int(df_relevant_data['ratings_count'].quantile(0.90))#minimum number of votes to be listed\n",
        "print(f'The average rating of all the books is {C} and the minimum number of votes required by the books to be listed is {m}  ')"
      ],
      "metadata": {
        "id": "GVOyGcstRFHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating weighted average rating of the books\n",
        "df_relevant_data['weighted_average']=round(((R*v)+ (C*m))/(v+m),2)"
      ],
      "metadata": {
        "id": "AUyXNoucRH3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_relevant_data.sort_values(by='weighted_average',ascending=False).head(10)"
      ],
      "metadata": {
        "id": "QhI80pKrRLU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the list of most favored books based on the weighted rating scores. The book 'Harry Potter and the Chamber of Secrets Postcard Book' seems to have top this chart."
      ],
      "metadata": {
        "id": "EOIw_PA-ROlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author based recommender system"
      ],
      "metadata": {
        "id": "ZueXJ44_RRyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def author_based(book_title,number,df_relevant_data=df_relevant_data):\n",
        "  '''\n",
        "  To recommend books from the same author as the book entered by the user\n",
        "  '''\n",
        "  author=df_relevant_data.loc[df_relevant_data['Book-Title']==book_title]['Book-Author'].unique()[0]\n",
        "  author_df=df_relevant_data.loc[(df_relevant_data['Book-Author']==author)].sort_values(by='weighted_average',ascending=False)\n",
        "  print(f'The author of the book {book_title} is {author}\\n')\n",
        "  print(f'Here are the top {number} books from the same author\\n')\n",
        "  top_rec=author_df.loc[(author_df['Book-Title']!=book_title),['Book-Title','weighted_average']].head(number)\n",
        "  return(top_rec)\n"
      ],
      "metadata": {
        "id": "D2wF-LOdRTRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get book name and number of books to recommend\n",
        "book_title = 'Harry Potter and the Chamber of Secrets (Book 2)'\n",
        "number =5\n",
        "author_based(book_title,number)\n",
        "# top_recommendations from the same author"
      ],
      "metadata": {
        "id": "PEgeNkVGRcfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collaborative filtering\n",
        "\n",
        "\n",
        "Collaborative filtering techniques create a model based on past user activity (items previously purchased, movies viewed and rated, etc.) as well as usage choices made by both current and past users. Then, this model is used to predict the ratings for items or items themselves that the user might be interested in."
      ],
      "metadata": {
        "id": "uPHYKOHDRhj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory Based Approach"
      ],
      "metadata": {
        "id": "lediJARiRplC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN Based Algorithm"
      ],
      "metadata": {
        "id": "wKeVYiz1Rtcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we kept running into memory issues, so decided to reduce some data by filtering things out\n",
        "# focussing on users with more than 3 ratings and top 10% most frequently rated books\n",
        "required_ratings = 3\n",
        "\n",
        "user = df['User-ID'].value_counts()\n",
        "user_list = user[user >required_ratings].index.to_list()\n",
        "filter_df = df[df['User-ID'].isin(user_list)]\n",
        "\n",
        "print('Number of users with ratings more than 3 are: {}'.format(filter_df.shape[0]))"
      ],
      "metadata": {
        "id": "dDhnlUvPRs-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10% most frequently rated books\n",
        "required = len(filter_df.ISBN.unique()) * 0.1\n",
        "\n",
        "user_list = filter_df['Book-Title'].value_counts().head(int(required)).index.to_list()\n",
        "filter_df = filter_df[filter_df['Book-Title'].isin(user_list)]\n",
        "\n",
        "print('Number of top 10% users are: {}'.format(filter_df.shape[0]))"
      ],
      "metadata": {
        "id": "coswDRzXR05X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of final dataset\n",
        "filter_df.shape"
      ],
      "metadata": {
        "id": "R2p7dkTgR35F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a pivot table\n",
        "table = filter_df.pivot_table(columns='User-ID', index='Book-Title', values='Book-Rating')\n",
        "table"
      ],
      "metadata": {
        "id": "HNpUtmjOR7a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling null values\n",
        "table.fillna(0, inplace=True)\n",
        "table"
      ],
      "metadata": {
        "id": "GnxjNvRGR_Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting to sparse matrix\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "sparse = csr_matrix(table)\n",
        "sparse"
      ],
      "metadata": {
        "id": "MipQxL3eSGeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an instance of KNN\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "model = NearestNeighbors(algorithm='brute')\n",
        "model.fit(sparse)"
      ],
      "metadata": {
        "id": "g5j_CYc_SKeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get recommendations\n",
        "\n",
        "def get_recommendations(name, n):\n",
        "\n",
        "  # getting book id\n",
        "  book_id= np.where(table.index==name)[0][0]\n",
        "\n",
        "  # distances and suggestions based on similarity\n",
        "  distances, suggestions = model.kneighbors(table.iloc[book_id, :].values.reshape(1,-1),n_neighbors=n+1)\n",
        "  suggestions = suggestions.flatten().tolist()\n",
        "\n",
        "  for i in range(len(suggestions)):\n",
        "    # if book is same as input\n",
        "    if i==0:\n",
        "      print('The top {} Recommended books for {} are:\\n'.format(n, name))\n",
        "    else:\n",
        "      print(table.index[suggestions[i]])\n",
        "  return"
      ],
      "metadata": {
        "id": "TYPV68qKSOV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_recommendations('Harry Potter and the Chamber of Secrets (Book 2)', 10)"
      ],
      "metadata": {
        "id": "d9w0dApvSR9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN with cosine metric"
      ],
      "metadata": {
        "id": "XLJZ3gYXScZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an instance of KNN with cosine metric\n",
        "\n",
        "model_cosine = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "model_cosine.fit(sparse)"
      ],
      "metadata": {
        "id": "isb8kg8ESf5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get recommendations\n",
        "\n",
        "def get_cosine_recommendations(name, n):\n",
        "\n",
        "  print('Cosine Similarity based recommendations.\\n')\n",
        "\n",
        "  # distances and indices based on similarity\n",
        "  distances, indices = model_cosine.kneighbors(table.loc[name].values.reshape(1, -1), n_neighbors = n+1)\n",
        "\n",
        "  for i in range(len(distances.flatten())):\n",
        "    if i==0:\n",
        "      print('The top {} Recommended books for {} are:\\n'.format(n, name))\n",
        "    else:\n",
        "      print(table.index[indices.flatten()[i]])\n",
        "  return"
      ],
      "metadata": {
        "id": "Y4JIliyvSizM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_cosine_recommendations('Harry Potter and the Chamber of Secrets (Book 2)', 10)"
      ],
      "metadata": {
        "id": "qw4tm_YASmh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN-Location based\n",
        "\n",
        "\n",
        "Using KNN algorithm, clusters of similar users based on common book ratings can be found and predictions can be made using the average rating of the top-k nearest neighbors."
      ],
      "metadata": {
        "id": "j5V98r0LSt4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_rating = df[['User-ID','ISBN','Book-Rating','Book-Title']]\n",
        "print(book_rating.info())\n",
        "print(book_rating.shape)\n",
        "print(book_rating.head())"
      ],
      "metadata": {
        "id": "kQIE43vrS1Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_rating = book_rating.dropna(axis=0, subset= ['Book-Title'])\n",
        "book_ratingCount = (book_rating.groupby(by = ['Book-Title'])['Book-Rating'].count().reset_index().rename(columns = {'Book-Rating' : 'totalRatingCount'})[['Book-Title', 'totalRatingCount']])\n",
        "book_ratingCount.head()"
      ],
      "metadata": {
        "id": "r5_yGm1mS4fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_with_totalRatingCount = book_rating.merge(book_ratingCount, left_on = 'Book-Title', right_on = 'Book-Title', how ='left')\n",
        "rating_with_totalRatingCount.head()"
      ],
      "metadata": {
        "id": "-I-1nVACTNHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "print(book_ratingCount['totalRatingCount'].describe())"
      ],
      "metadata": {
        "id": "Sry_VTlyTRBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(book_ratingCount['totalRatingCount'].quantile(np.arange(.9, 1, .01)))"
      ],
      "metadata": {
        "id": "EEq41ChPTU3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "popularity_threshold = 100\n",
        "rating_popular_book = rating_with_totalRatingCount[rating_with_totalRatingCount['totalRatingCount'] >= popularity_threshold]\n",
        "rating_popular_book.head()"
      ],
      "metadata": {
        "id": "iQlBZ5yYTscO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering to users in top 2 countries - US & Canada"
      ],
      "metadata": {
        "id": "VBMR8RFxTx7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined = rating_popular_book.merge(users_df, left_on ='User-ID', right_on= 'User-ID', how='left')\n",
        "\n",
        "us_canada_user_rating = combined[combined['Country'].str.contains(\"USA|CANADA\")]\n",
        "us_canada_user_rating = us_canada_user_rating.drop('Age', axis = 1)\n",
        "\n",
        "us_canada_user_rating.head()"
      ],
      "metadata": {
        "id": "VV54fQOvT29n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing KNN"
      ],
      "metadata": {
        "id": "P6nEUEEjUKag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_user_rating = us_canada_user_rating.drop_duplicates(['User-ID', 'Book-Title'])\n",
        "us_canada_user_rating_pivot = us_canada_user_rating.pivot_table(index = 'Book-Title', columns= 'User-ID', values = 'Book-Rating').fillna(0)\n",
        "us_canada_user_rating_matrix = csr_matrix(us_canada_user_rating_pivot.values)"
      ],
      "metadata": {
        "id": "kdwf_1rvUOoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\n",
        "model_knn.fit(us_canada_user_rating_matrix)"
      ],
      "metadata": {
        "id": "wfjCqZ5fUSmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_index = np.random.choice(us_canada_user_rating_pivot.shape[0])\n",
        "distances, indices = model_knn.kneighbors(us_canada_user_rating_pivot.iloc[query_index, :].values.reshape(1, -1), n_neighbors=6)\n",
        "\n",
        "for i in range(0, len(distances.flatten())):\n",
        "    if i==0:\n",
        "        print('Recommendations for', format(us_canada_user_rating_pivot.index[query_index]), ':')\n",
        "    else:\n",
        "        print('{0}: {1}, with distance of {2}:'.format(i, us_canada_user_rating_pivot.index[indices.flatten()[i]],distances.flatten()[i]))"
      ],
      "metadata": {
        "id": "InmewGKuUWX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Based Approach"
      ],
      "metadata": {
        "id": "ghX1od9Ix74r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Singular Value Decomposition"
      ],
      "metadata": {
        "id": "Y5-VDTasyCoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse.linalg import svds\n",
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "9UoHXi1wyBkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering books with more than 5 reviews\n",
        "\n",
        "print('The number of books that are explicitely rated are',explicit_rating['ISBN'].nunique())\n",
        "ratings_count_df=explicit_rating.groupby(\"ISBN\")['User-ID'].count().to_frame('No-of-rated-users').reset_index()\n",
        "selected_books =list(ratings_count_df.loc[ratings_count_df['No-of-rated-users']>5,'ISBN'].unique())\n",
        "print('Number of  books rated by atleast 5 users:',len(selected_books))\n",
        "filter_df=explicit_rating.loc[explicit_rating['ISBN'].isin(selected_books)]"
      ],
      "metadata": {
        "id": "qp0kSHppyT4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#keeping books with selected users\n",
        "print('The number of users who have explicitely rated books are',explicit_rating['User-ID'].nunique())\n",
        "\n",
        "#keeps Users who have rated more than five books\n",
        "books_count_df=filter_df.groupby(\"User-ID\")['ISBN'].count().to_frame('No-of-books-rated').reset_index()\n",
        "selected_users = list(books_count_df.loc[books_count_df['No-of-books-rated']>5,'User-ID'].unique())\n",
        "print('Number of  users who have rated atleast 5 books are :',len(selected_users))\n",
        "\n",
        "#dataframe with filtered number of interactions\n",
        "filter_df=filter_df.loc[filter_df['User-ID'].isin(selected_users)]\n",
        "print('The shape of data fame with filtered number of interactions : ',filter_df.shape)"
      ],
      "metadata": {
        "id": "VVLaTR2lyZXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_df = filter_df.copy()"
      ],
      "metadata": {
        "id": "icqChkVuycbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_df['Book-Rating'].describe()"
      ],
      "metadata": {
        "id": "HXZqRuzGyhS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_user_preference(x):\n",
        "    '''Function to smooth column'''\n",
        "    return math.log(1+x, 2)\n",
        "#applying function\n",
        "complete_df['Book-Rating']= complete_df['Book-Rating'].apply(smooth_user_preference)\n",
        "complete_df.head()"
      ],
      "metadata": {
        "id": "04kqVahuyktn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(complete_df,\n",
        "                                   stratify=complete_df['User-ID'],\n",
        "                                   test_size=0.20,\n",
        "                                   random_state=0)\n",
        "\n",
        "print('# interactions on Train set: %d' % len(train_df))\n",
        "print('# interactions on Test set: %d' % len(test_df))"
      ],
      "metadata": {
        "id": "oP-ToTpAypr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying the first 5 rows of test set\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "HWG7TDRhytP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a sparse pivot table with users in rows and ISBN number of books in columns\n",
        "users_books_pivot_matrix_df = train_df.pivot(index='User-ID',\n",
        "                                                          columns='ISBN',\n",
        "                                                          values='Book-Rating').fillna(0)\n",
        "\n",
        "users_books_pivot_matrix_df.head()"
      ],
      "metadata": {
        "id": "HiyVuBY_ywSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a matrix with the values of users_books_pivot_matrix_df\n",
        "original_ratings_matrix = users_books_pivot_matrix_df.values\n",
        "original_ratings_matrix[:10]"
      ],
      "metadata": {
        "id": "S98WgwCxy0Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the User-IDs in a list\n",
        "user_ids = list(users_books_pivot_matrix_df.index)\n",
        "user_ids[:10]"
      ],
      "metadata": {
        "id": "UMtzA8HOy2ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of factors to factor the user-item matrix.\n",
        "NUMBER_OF_FACTORS_MF = 20\n",
        "\n",
        "#Performs matrix factorization of the original user item matrix\n",
        "U, sigma, Vt = svds(original_ratings_matrix, k = NUMBER_OF_FACTORS_MF)"
      ],
      "metadata": {
        "id": "IS2jum-uy5mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting sigma to a diagonal matrix\n",
        "sigma = np.diag(sigma)"
      ],
      "metadata": {
        "id": "MIyJconVy7_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the factorization, we try to to reconstruct the original matrix by multiplying its factors. The resulting matrix is not sparse any more. It has generated rating predictions for books with which users have not yet interacted (and therefore not rated), which we will use to recommend relevant books to the user."
      ],
      "metadata": {
        "id": "XPxvkIWozCXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rating matric reconstructed using the matrices obtained after factorizing\n",
        "predicted_ratings_matrix = np.dot(np.dot(U, sigma), Vt)\n",
        "predicted_ratings_matrix"
      ],
      "metadata": {
        "id": "ETVp74bIzF8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the reconstructed matrix back to a Pandas dataframe\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings_matrix , columns = users_books_pivot_matrix_df.columns, index=user_ids).transpose()\n",
        "predicted_ratings_df.head()"
      ],
      "metadata": {
        "id": "fnJu-A4szIzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSE8gBjk4fFA"
      },
      "source": [
        "### **Building the Recommender model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CFRecommender:\n",
        "    #Storing model name\n",
        "    MODEL_NAME = 'Collaborative Filtering'\n",
        "\n",
        "    def __init__(self, cf_predictions_df, items_df=None):\n",
        "        #Creating attributes\n",
        "        self.cf_predictions_df = cf_predictions_df\n",
        "        self.items_df = items_df\n",
        "\n",
        "    def get_model_name(self):\n",
        "        '''This will return model name'''\n",
        "        return self.MODEL_NAME\n",
        "\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        # Get and sort the user's predictions\n",
        "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False).reset_index().rename(columns={user_id: 'Book-Rating'})\n",
        "\n",
        "        # Recommend the highest predicted rating content that the user hasn't seen yet.\n",
        "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['ISBN'].isin(items_to_ignore)].sort_values('Book-Rating', ascending = False).head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            #runs only if verbose=True\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "            #Merging\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left',\n",
        "                                                          left_on = 'ISBN',\n",
        "                                                          right_on = 'ISBN')[[\"ISBN\",'Book-Title',\t'Book-Author','Publisher']]\n",
        "\n",
        "        return recommendations_df\n",
        "\n",
        "#Creating object of the class\n",
        "cf_recommender_model = CFRecommender(predicted_ratings_df, books_df)"
      ],
      "metadata": {
        "id": "EXhAH5KX0i_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_items_interacted(person_id, interactions_df):\n",
        "    '''\n",
        "    This function will take user id as input and return interacted items\n",
        "    '''\n",
        "    interacted_items = interactions_df.loc[person_id]['ISBN']\n",
        "    #Repetation is avoided by taking set\n",
        "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
      ],
      "metadata": {
        "id": "oWAsQDaU0yiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Indexing by personId to speed up the searches during evaluation\n",
        "full_indexed_df =complete_df.set_index('User-ID')\n",
        "train_indexed_df = train_df.set_index('User-ID')\n",
        "test_indexed_df = test_df.set_index('User-ID')"
      ],
      "metadata": {
        "id": "0N5RGvib02PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Let's predict the relevant books for User ID 254.Before that,let's see the list of books that were already rated/purchased by this user.\n"
      ],
      "metadata": {
        "id": "2PH_PzTo082J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The books that were already rated by this user\n",
        "print(f'These are  books that the user ID {user_ids[3]} has already rated \\n')\n",
        "books_df.loc[books_df['ISBN'].isin(list(get_items_interacted(user_ids[3],train_indexed_df)))]['Book-Title']"
      ],
      "metadata": {
        "id": "sTGW4PJj1BAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recommendation for a single user\n",
        "print(f'Recommending books for User ID: {user_ids[3]} ')\n",
        "cf_recommender_model.recommend_items(user_ids[3],items_to_ignore= get_items_interacted(user_ids[3],train_indexed_df),verbose=True)"
      ],
      "metadata": {
        "id": "o2h1NNV01G0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "IAybXO3d1IoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for getting the set of books which a user has not interacted with\n",
        "def get_not_interacted_items_sample(person_id, sample_size, seed=42):\n",
        "    #Storing interacted items\n",
        "    interacted_items = get_items_interacted(person_id, full_indexed_df)\n",
        "    #Getting set of all items\n",
        "    all_items=set(full_indexed_df[\"ISBN\"])\n",
        "    #Obtaining non interacted items\n",
        "    non_interacted_items = all_items - interacted_items\n",
        "\n",
        "    random.seed(seed)\n",
        "    #Selecting random sample of given sample_size\n",
        "    non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "    return set(non_interacted_items_sample)"
      ],
      "metadata": {
        "id": "kAxb1L-d1Xn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top-N accuracy metrics\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
        "\n",
        "class ModelEvaluator:\n",
        "\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "            try:\n",
        "                #Stores index of item id if it is present in the recommended_items\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                #If item id is not found in the recommended list\n",
        "                index = -1\n",
        "            #checking whether index is present in the topN items or not\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, person_id):\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = test_indexed_df.loc[person_id]\n",
        "\n",
        "        #Obtaining unique interacted items by the user\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set([(interacted_values_testset['ISBN'])])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        person_recs_df = model.recommend_items(person_id, items_to_ignore=get_items_interacted(person_id, train_indexed_df),topn=10000000000)\n",
        "\n",
        "        hits_at_5_count = 0\n",
        "        hits_at_10_count = 0\n",
        "\n",
        "        # For each item the user has interacted in test set\n",
        "        for item_id in person_interacted_items_testset:\n",
        "\n",
        "            # Getting a random sample of 100 items the user has not interacted with\n",
        "            non_interacted_items_sample = get_not_interacted_items_sample(person_id, sample_size=100, seed=42)\n",
        "\n",
        "            # Combining the current interacted item with the 100 random items\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
        "\n",
        "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
        "            valid_recs_df = person_recs_df[person_recs_df['ISBN'].isin(items_to_filter_recs)]\n",
        "            valid_recs = valid_recs_df['ISBN'].values\n",
        "\n",
        "            # Verifying if the current interacted item is among the Top-N recommended items\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
        "            #Counting hit at 5\n",
        "            hits_at_5_count += hit_at_5\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
        "            #Counting hit at 10\n",
        "            hits_at_10_count += hit_at_10\n",
        "\n",
        "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
        "\n",
        "        #Creating a dictionary\n",
        "        person_metrics = {'hits@5_count':hits_at_5_count,\n",
        "                          'hits@10_count':hits_at_10_count,\n",
        "                          'interacted_count': interacted_items_count_testset,\n",
        "                          'recall@5': recall_at_5,\n",
        "                          'recall@10': recall_at_10}\n",
        "        return person_metrics\n",
        "\n",
        "\n",
        "    # Function to evaluate the performance of model at overall level\n",
        "    def evaluate_model(self, model):\n",
        "\n",
        "        people_metrics = []\n",
        "\n",
        "        #Calculating metrics for all users in the test set\n",
        "        for idx, person_id in enumerate(list(test_indexed_df.index.unique().values)):\n",
        "            #Returns dictionary containing person_metrics for each user\n",
        "            person_metrics = self.evaluate_model_for_user(model, person_id)\n",
        "            #Adds user_id to the dictionary\n",
        "            person_metrics['_person_id'] = person_id\n",
        "            #Appends each dictionary to the list\n",
        "            people_metrics.append(person_metrics)\n",
        "\n",
        "        print('%d users processed' % idx)\n",
        "        #Creates dataframe containing value of metrics for all the users using the list of dictionaries\n",
        "        detailed_results_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
        "\n",
        "        #Calculating global recall@5 and global recall@10\n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "\n",
        "        #Creates dictionary containing global metrics\n",
        "        global_metrics = {'modelName': model.get_model_name(),\n",
        "                          'recall@5': global_recall_at_5,\n",
        "                          'recall@10': global_recall_at_10}\n",
        "        return global_metrics, detailed_results_df\n",
        "\n",
        "model_evaluator = ModelEvaluator()"
      ],
      "metadata": {
        "id": "sed1JKsp1qwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
        "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
        "\n",
        "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
        "cf_detailed_results_df.head(10)"
      ],
      "metadata": {
        "id": "RPDmz_y21xo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "LxB5diVv2rkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   \n",
        "\n",
        "    The initial step,of our project was Data preprocessing of the three datasets-books_df,users_df and ratings_df,wherein we removed duplicates and imputed the missing values & invalid entries with appropriate values,corrected spellings.\n",
        "\n",
        "*   Then,we performed Exploratory Data Analysis to find out the countries with maximum users,popular books,popular authors and popular publishing companies.We also analysed the rating distribution,age distribution of users and the popular books amongst various age groups .\n",
        "\n",
        "*   Then,we used Popularity-based approach,Collaborative filtering approach to built different types of recommendation models.\n",
        "\n",
        "\n",
        "\n",
        "*   We evaluated the performance of Singular Value Decomposition based recommender and obtained a Global Recall@5 of 30 % and Recall@10 of 41%\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RtMbYNFY2zIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}